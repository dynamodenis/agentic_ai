{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to Week 6 Day 3!\n",
    "\n",
    "Let's experiment with a bunch more MCP Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace\n",
    "from agents.mcp import MCPServerStdio\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first type of MCP Server: runs locally, everything local\n",
    "\n",
    "Here's a really interesting one: a knowledge-graph based memory.\n",
    "\n",
    "It's a persistent memory store of entities, observations about them, and relationships between them.\n",
    "\n",
    "https://github.com/modelcontextprotocol/servers/tree/main/src/memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error initializing MCP server: Connection closed\n"
     ]
    },
    {
     "ename": "McpError",
     "evalue": "Connection closed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMcpError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m params = {\u001b[33m\"\u001b[39m\u001b[33mcommand\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mnpx\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33margs\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33m-y\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m@mcp/memory-server-libsql\u001b[39m\u001b[33m\"\u001b[39m],\u001b[33m\"\u001b[39m\u001b[33menv\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mLIBSQL_URL\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mfile:./memory/denis.db\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m MCPServerStdio(params=params, client_session_timeout_seconds=\u001b[32m30\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m server:\n\u001b[32m      4\u001b[39m     mcp_tools = \u001b[38;5;28;01mawait\u001b[39;00m server.list_tools()\n\u001b[32m      6\u001b[39m mcp_tools\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/agentic-ai/agents/.venv/lib/python3.12/site-packages/agents/mcp/server.py:98\u001b[39m, in \u001b[36m_MCPServerWithClientSession.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.connect()\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/agentic-ai/agents/.venv/lib/python3.12/site-packages/agents/mcp/server.py:126\u001b[39m, in \u001b[36m_MCPServerWithClientSession.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    115\u001b[39m read, write, *_ = transport\n\u001b[32m    117\u001b[39m session = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.exit_stack.enter_async_context(\n\u001b[32m    118\u001b[39m     ClientSession(\n\u001b[32m    119\u001b[39m         read,\n\u001b[32m   (...)\u001b[39m\u001b[32m    124\u001b[39m     )\n\u001b[32m    125\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m server_result = \u001b[38;5;28;01mawait\u001b[39;00m session.initialize()\n\u001b[32m    127\u001b[39m \u001b[38;5;28mself\u001b[39m.server_initialize_result = server_result\n\u001b[32m    128\u001b[39m \u001b[38;5;28mself\u001b[39m.session = session\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/agentic-ai/agents/.venv/lib/python3.12/site-packages/mcp/client/session.py:123\u001b[39m, in \u001b[36mClientSession.initialize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    113\u001b[39m sampling = types.SamplingCapability() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampling_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _default_sampling_callback \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    114\u001b[39m roots = (\n\u001b[32m    115\u001b[39m     \u001b[38;5;66;03m# TODO: Should this be based on whether we\u001b[39;00m\n\u001b[32m    116\u001b[39m     \u001b[38;5;66;03m# _will_ send notifications, or only whether\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    121\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send_request(\n\u001b[32m    124\u001b[39m     types.ClientRequest(\n\u001b[32m    125\u001b[39m         types.InitializeRequest(\n\u001b[32m    126\u001b[39m             method=\u001b[33m\"\u001b[39m\u001b[33minitialize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    127\u001b[39m             params=types.InitializeRequestParams(\n\u001b[32m    128\u001b[39m                 protocolVersion=types.LATEST_PROTOCOL_VERSION,\n\u001b[32m    129\u001b[39m                 capabilities=types.ClientCapabilities(\n\u001b[32m    130\u001b[39m                     sampling=sampling,\n\u001b[32m    131\u001b[39m                     experimental=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    132\u001b[39m                     roots=roots,\n\u001b[32m    133\u001b[39m                 ),\n\u001b[32m    134\u001b[39m                 clientInfo=\u001b[38;5;28mself\u001b[39m._client_info,\n\u001b[32m    135\u001b[39m             ),\n\u001b[32m    136\u001b[39m         )\n\u001b[32m    137\u001b[39m     ),\n\u001b[32m    138\u001b[39m     types.InitializeResult,\n\u001b[32m    139\u001b[39m )\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.protocolVersion \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_PROTOCOL_VERSIONS:\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnsupported protocol version from the server: \u001b[39m\u001b[33m\"\u001b[39m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.protocolVersion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/agentic-ai/agents/.venv/lib/python3.12/site-packages/mcp/shared/session.py:286\u001b[39m, in \u001b[36mBaseSession.send_request\u001b[39m\u001b[34m(self, request, result_type, request_read_timeout_seconds, metadata, progress_callback)\u001b[39m\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m McpError(\n\u001b[32m    275\u001b[39m         ErrorData(\n\u001b[32m    276\u001b[39m             code=httpx.codes.REQUEST_TIMEOUT,\n\u001b[32m   (...)\u001b[39m\u001b[32m    282\u001b[39m         )\n\u001b[32m    283\u001b[39m     )\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response_or_error, JSONRPCError):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m McpError(response_or_error.error)\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result_type.model_validate(response_or_error.result)\n",
      "\u001b[31mMcpError\u001b[39m: Connection closed"
     ]
    }
   ],
   "source": [
    "params = {\"command\": \"npx\",\"args\": [\"-y\", \"mcp-memory-libsql\"],\"env\": {\"LIBSQL_URL\": \"file:./memory/denis.db\"}}\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "\n",
    "mcp_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You use your entity tools as a persistent memory to store and recall information about your conversations.\"\n",
    "request = \"My name's Denis. I'm an LLM engineer. I'm teaching a course about AI Agents, including the incredible MCP protocol. \\\n",
    "MCP is a protocol for connecting agents with tools, resources and prompt templates, and makes it easy to integrate AI agents with capabilities.\"\n",
    "model = \"gpt-4.1-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, \"My name's Ed. What do you know about me?\")\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the trace:\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 2nd type of MCP server - runs locally, calls a web service\n",
    "\n",
    "### Brave Search - apologies - this will need another API key! But it's free again.\n",
    "\n",
    "https://brave.com/search/api/\n",
    "\n",
    "Set up your account, and put your key in the .env under `BRAVE_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error initializing MCP server: Connection closed\n"
     ]
    },
    {
     "ename": "McpError",
     "evalue": "Connection closed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMcpError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# print(\"üß™ Test 1: Running npx directly...\")\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#     result = subprocess.run(\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m \u001b[38;5;66;03m#     import traceback\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m#     traceback.print_exc()\u001b[39;00m\n\u001b[32m     57\u001b[39m params = {\u001b[33m\"\u001b[39m\u001b[33mcommand\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mnpx\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33margs\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33m-y\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m@modelcontextprotocol/server-brave-search\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33menv\u001b[39m\u001b[33m\"\u001b[39m: env}\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m MCPServerStdio(params=params, client_session_timeout_seconds=\u001b[32m60\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m server:\n\u001b[32m     60\u001b[39m     mcp_tools = \u001b[38;5;28;01mawait\u001b[39;00m server.list_tools()\n\u001b[32m     62\u001b[39m mcp_tools\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/agentic-ai/agents/.venv/lib/python3.12/site-packages/agents/mcp/server.py:98\u001b[39m, in \u001b[36m_MCPServerWithClientSession.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.connect()\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/agentic-ai/agents/.venv/lib/python3.12/site-packages/agents/mcp/server.py:126\u001b[39m, in \u001b[36m_MCPServerWithClientSession.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    115\u001b[39m read, write, *_ = transport\n\u001b[32m    117\u001b[39m session = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.exit_stack.enter_async_context(\n\u001b[32m    118\u001b[39m     ClientSession(\n\u001b[32m    119\u001b[39m         read,\n\u001b[32m   (...)\u001b[39m\u001b[32m    124\u001b[39m     )\n\u001b[32m    125\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m server_result = \u001b[38;5;28;01mawait\u001b[39;00m session.initialize()\n\u001b[32m    127\u001b[39m \u001b[38;5;28mself\u001b[39m.server_initialize_result = server_result\n\u001b[32m    128\u001b[39m \u001b[38;5;28mself\u001b[39m.session = session\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/agentic-ai/agents/.venv/lib/python3.12/site-packages/mcp/client/session.py:123\u001b[39m, in \u001b[36mClientSession.initialize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    113\u001b[39m sampling = types.SamplingCapability() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampling_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _default_sampling_callback \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    114\u001b[39m roots = (\n\u001b[32m    115\u001b[39m     \u001b[38;5;66;03m# TODO: Should this be based on whether we\u001b[39;00m\n\u001b[32m    116\u001b[39m     \u001b[38;5;66;03m# _will_ send notifications, or only whether\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    121\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send_request(\n\u001b[32m    124\u001b[39m     types.ClientRequest(\n\u001b[32m    125\u001b[39m         types.InitializeRequest(\n\u001b[32m    126\u001b[39m             method=\u001b[33m\"\u001b[39m\u001b[33minitialize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    127\u001b[39m             params=types.InitializeRequestParams(\n\u001b[32m    128\u001b[39m                 protocolVersion=types.LATEST_PROTOCOL_VERSION,\n\u001b[32m    129\u001b[39m                 capabilities=types.ClientCapabilities(\n\u001b[32m    130\u001b[39m                     sampling=sampling,\n\u001b[32m    131\u001b[39m                     experimental=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    132\u001b[39m                     roots=roots,\n\u001b[32m    133\u001b[39m                 ),\n\u001b[32m    134\u001b[39m                 clientInfo=\u001b[38;5;28mself\u001b[39m._client_info,\n\u001b[32m    135\u001b[39m             ),\n\u001b[32m    136\u001b[39m         )\n\u001b[32m    137\u001b[39m     ),\n\u001b[32m    138\u001b[39m     types.InitializeResult,\n\u001b[32m    139\u001b[39m )\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.protocolVersion \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_PROTOCOL_VERSIONS:\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnsupported protocol version from the server: \u001b[39m\u001b[33m\"\u001b[39m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.protocolVersion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/agentic-ai/agents/.venv/lib/python3.12/site-packages/mcp/shared/session.py:286\u001b[39m, in \u001b[36mBaseSession.send_request\u001b[39m\u001b[34m(self, request, result_type, request_read_timeout_seconds, metadata, progress_callback)\u001b[39m\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m McpError(\n\u001b[32m    275\u001b[39m         ErrorData(\n\u001b[32m    276\u001b[39m             code=httpx.codes.REQUEST_TIMEOUT,\n\u001b[32m   (...)\u001b[39m\u001b[32m    282\u001b[39m         )\n\u001b[32m    283\u001b[39m     )\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response_or_error, JSONRPCError):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m McpError(response_or_error.error)\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result_type.model_validate(response_or_error.result)\n",
      "\u001b[31mMcpError\u001b[39m: Connection closed"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "import subprocess\n",
    "import asyncio\n",
    "env = os.environ.copy()\n",
    "env[\"BRAVE_API_KEY\"] = os.getenv(\"BRAVE_API_KEY\")\n",
    "\n",
    "# print(\"üß™ Test 1: Running npx directly...\")\n",
    "# try:\n",
    "#     result = subprocess.run(\n",
    "#         [\"npx\", \"--version\"],\n",
    "#         capture_output=True,\n",
    "#         text=True,\n",
    "#         timeout=5\n",
    "#     )\n",
    "#     print(f\"‚úÖ npx version: {result}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"‚ùå npx failed: {e}\")\n",
    "\n",
    "# try:\n",
    "#     # Start the server process\n",
    "#     process = subprocess.Popen(\n",
    "#         [\"npx\", \"-y\", \"@modelcontextprotocol/server-brave-search\"],\n",
    "#         env=env,\n",
    "#         stdin=subprocess.PIPE,\n",
    "#         stdout=subprocess.PIPE,\n",
    "#         stderr=subprocess.PIPE,\n",
    "#         text=True\n",
    "#     )\n",
    "    \n",
    "#     # Wait a bit and check if it's running\n",
    "#     await asyncio.sleep(2)\n",
    "    \n",
    "#     if process.poll() is None:\n",
    "#         print(\"‚úÖ Server process started successfully\")\n",
    "        \n",
    "#         # Check stderr for any messages\n",
    "#         import select\n",
    "#         if select.select([process.stderr], [], [], 0)[0]:\n",
    "#             stderr = process.stderr.read()\n",
    "#             print(f\"üìã Server stderr: {stderr}\")\n",
    "        \n",
    "#         process.terminate()\n",
    "#         process.wait()\n",
    "#     else:\n",
    "#         # Process died immediately\n",
    "#         stdout, stderr = process.communicate()\n",
    "#         print(f\"‚ùå Server process died immediately\")\n",
    "#         print(f\"   stdout: {stdout}\")\n",
    "#         print(f\"   stderr: {stderr}\")\n",
    "#         print(f\"   return code: {process.returncode}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"‚ùå Failed to start server: {e}\")\n",
    "#     import traceback\n",
    "#     traceback.print_exc()\n",
    "\n",
    "params = {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-brave-search\"], \"env\": env}\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=60) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "\n",
    "mcp_tools\n",
    "\n",
    "# env = {\"BRAVE_API_KEY\": os.getenv(\"BRAVE_API_KEY\")}\n",
    "# params = {\"command\": \"npx\", \"args\": [\"-y\", \"@brave/brave-search-mcp-server\", \"--transport\", \"http\"], \"env\": env}\n",
    "\n",
    "# async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as server:\n",
    "#     mcp_tools = await server.list_tools()\n",
    "\n",
    "# mcp_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You are able to search the web for information and briefly summarize the takeaways.\"\n",
    "request = f\"Please research the latest news on Amazon stock price and briefly summarize its outlook. \\\n",
    "For context, the current date is {datetime.now().strftime('%Y-%m-%d')}\"\n",
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As usual, check out the trace:\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now the third type: running remotely\n",
    "\n",
    "It's actually really hard to find a \"remote MCP server\" aka \"hosted MCP server\" aka \"managed MCP server\".\n",
    "\n",
    "It's not a common model for using or sharing MCP servers, and there isn't a standard way to discover remote MCP servers.\n",
    "\n",
    "Anthropic lists some remote MCP servers, but these are for paid applications with business users:\n",
    "\n",
    "https://docs.anthropic.com/en/docs/agents-and-tools/remote-mcp-servers\n",
    "\n",
    "CloudFlare has tooling for you to create and deploy your own remote MCP servers, but this does not seem to be a common practice:\n",
    "\n",
    "https://developers.cloudflare.com/agents/guides/remote-mcp-server/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And back to the 2nd type: the Polygon.io MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">PLEASE READ!!-</h2>\n",
    "            <span style=\"color:#ff7800;\">This service for financial market data has both a FREE plan and a PAID plan, and we can use either depending on your appetite.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW SECTION: Introducing polygon.io\n",
    "\n",
    "Polygon.io is a hugely popular financial data provider. It has a free plan and a paid plan. And it also has an MCP Server!\n",
    "\n",
    "First, read up on polygon.io on their excellent website, including looking at their pricing:\n",
    "\n",
    "https://polygon.io\n",
    "\n",
    "### Polygon.io Part 1: Polygon.io free service (the paid will be totally optional, of course!)\n",
    "\n",
    "1. Please sign up for polygon.io (top right)  \n",
    "2. Once signed in, please select \"Keys\" in the left hand navigation\n",
    "3. Press the blue \"New Key\" button\n",
    "4. Copy the key name\n",
    "5. Edit your .env file and add the row:\n",
    "\n",
    "`POLYGON_API_KEY=xxxx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dotenv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mload_dotenv\u001b[49m(override=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      2\u001b[39m polygon_api_key = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mPOLYGON_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m polygon_api_key:\n",
      "\u001b[31mNameError\u001b[39m: name 'load_dotenv' is not defined"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "polygon_api_key = os.getenv(\"POLYGON_API_KEY\")\n",
    "if not polygon_api_key:\n",
    "    print(\"POLYGON_API_KEY is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreviousCloseAgg(ticker='AAPL', close=275.25, high=275.91, low=269.8, open=269.81, timestamp=1762894800000, volume=46201578.0, vwap=274.0648)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from polygon import RESTClient\n",
    "client = RESTClient(polygon_api_key)\n",
    "client.get_previous_close_agg(\"AAPL\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapped into a python module that caches end of day prices\n",
    "\n",
    "I've made a python module `market.py` that uses this API to look up share prices.\n",
    "\n",
    "But the free API is quite heavily rate limited - so I've been a bit sneaky; when you ask for a share price, this function retrieves the entire end-of-day equity market, and caches it in our database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275.25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from market import get_share_price\n",
    "get_share_price(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no rate limiting concerns!\n",
    "\n",
    "for i in range(1000):\n",
    "    get_share_price(\"AAPL\")\n",
    "get_share_price(\"AAPL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And I've made this into an MCP Server\n",
    "\n",
    "Just as we did with accounts.py; see `market_server.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"command\": \"uv\", \"args\": [\"run\", \"market_server.py\"]}\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=60) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "mcp_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try it out!\n",
    "\n",
    "Hopefully gpt-4o-mini is smart enough to know that the symbol for Apple is AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You answer questions about the stock market.\"\n",
    "request = \"What's the share price of Apple?\"\n",
    "model = \"gpt-4.1-mini\"\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=60) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polygon.io Part 2: Paid Plan - Totally Optional!\n",
    "\n",
    "If you are interested, you can subscribe to the monthly plan to get more up to date market data, and unlimited API calls.\n",
    "\n",
    "If you do wish to do this, then it also makes sense to use the full MCP server that Polygon.io has released, to take advantage of all their functionality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'polygon_api_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m params = {\u001b[33m\"\u001b[39m\u001b[33mcommand\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muvx\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      2\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33margs\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33m--from\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgit+https://github.com/polygon-io/mcp_polygon@v0.1.0\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmcp_polygon\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33menv\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mPOLYGON_API_KEY\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mpolygon_api_key\u001b[49m}\n\u001b[32m      4\u001b[39m           }\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m MCPServerStdio(params=params, client_session_timeout_seconds=\u001b[32m60\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m server:\n\u001b[32m      6\u001b[39m     mcp_tools = \u001b[38;5;28;01mawait\u001b[39;00m server.list_tools()\n",
      "\u001b[31mNameError\u001b[39m: name 'polygon_api_key' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "params = {\"command\": \"uvx\",\n",
    "          \"args\": [\"--from\", \"git+https://github.com/polygon-io/mcp_polygon@v0.1.0\", \"mcp_polygon\"],\n",
    "          \"env\": {\"POLYGON_API_KEY\": polygon_api_key}\n",
    "          }\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=60) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "mcp_tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wow that's a lot of tools!\n",
    "\n",
    "Let's try them out - hopefully the sheer number of tools doesn't overwhelm gpt-4o-mini!\n",
    "\n",
    "With the $29 monthly plan, we don't have access to some of the APIs, so I've needed to specify which APIs can be called.\n",
    "\n",
    "If you've splashed out on a bigger plan, feel free to remove my extra constraint.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You answer questions about the stock market.\"\n",
    "request = \"What's the share price of Apple? Use your get_snapshot_ticker tool to get the latest price.\"\n",
    "model = \"gpt-4.1-mini\"\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=60) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up your .env file\n",
    "\n",
    "If you do decide to have a paid plan, please add this to your .env file to indicate:\n",
    "\n",
    "`POLYGON_PLAN=paid`\n",
    "\n",
    "And if you decide to go all the way for the realtime API, then please do:\n",
    "\n",
    "`POLYGON_PLAN=realtime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "polygon_plan = os.getenv(\"POLYGON_PLAN\")\n",
    "is_paid_polygon = polygon_plan == \"paid\"\n",
    "is_realtime_polygon = polygon_plan == \"realtime\"\n",
    "\n",
    "if is_paid_polygon:\n",
    "    print(\"You've chosen to subscribe to the paid Polygon plan, so the code will look at prices on a 15 min delay\")\n",
    "elif is_realtime_polygon:\n",
    "    print(\"Wowzer - you've chosen to subscribe to the realtime Polygon plan, so the code will look at realtime prices\")\n",
    "else:\n",
    "    print(\"According to your .env file, you've chosen to subscribe to the free Polygon plan, so the code will look at EOD prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And that's it for today!\n",
    "\n",
    "I've removed the part of this lab that uses the \"Financial Datasets\" mcp server, because it's inferior - more expensive with fewer APIs.\n",
    "\n",
    "And this way we get to use the same provider for Free and Paid APIs.\n",
    "\n",
    "But if you want to see the code, just look in the git history for a prior version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercises</h2>\n",
    "            <span style=\"color:#ff7800;\">Explore MCP server marketplaces and integrate your own, using all 3 approaches.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
